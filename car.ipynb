{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spoken-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example loads the CAR ISR and attempts to run inference\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collect-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load CAR/modules.py\n",
    "import functools\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import requests\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "LEAKY_FACTOR = 0.2\n",
    "MULT_FACTOR = 1\n",
    "\n",
    "\n",
    "# TEST PASSED\n",
    "class PixelUnShuffle(nn.Module):\n",
    "    \"\"\"\n",
    "    Inverse process of pytorch pixel shuffle module\n",
    "    \"\"\"\n",
    "    def __init__(self, down_scale):\n",
    "        \"\"\"\n",
    "        :param down_scale: int, down scale factor\n",
    "        \"\"\"\n",
    "        super(PixelUnShuffle, self).__init__()\n",
    "\n",
    "        if not isinstance(down_scale, int):\n",
    "            raise ValueError('Down scale factor must be a integer number')\n",
    "        self.down_scale = down_scale\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        :param input: tensor of shape (batch size, channels, height, width)\n",
    "        :return: tensor of shape(batch size, channels * down_scale * down_scale, height / down_scale, width / down_scale)\n",
    "        \"\"\"\n",
    "        b, c, h, w = input.size()\n",
    "        assert h % self.down_scale == 0\n",
    "        assert w % self.down_scale == 0\n",
    "\n",
    "        oc = c * self.down_scale ** 2\n",
    "        oh = int(h / self.down_scale)\n",
    "        ow = int(w / self.down_scale)\n",
    "\n",
    "        output_reshaped = input.reshape(b, c, oh, self.down_scale, ow, self.down_scale)\n",
    "        output = output_reshaped.permute(0, 1, 3, 5, 2, 4).reshape(b, oc, oh, ow)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class DownsampleBlock(nn.Module):\n",
    "    def __init__(self, scale, input_channels, output_channels, ksize=1):\n",
    "        super(DownsampleBlock, self).__init__()\n",
    "        self.downsample = nn.Sequential(\n",
    "            PixelUnShuffle(scale),\n",
    "            nn.Conv2d(input_channels * (scale ** 2), output_channels, kernel_size=ksize, stride=1, padding=ksize//2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.downsample(input)\n",
    "\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, scale, input_channels, output_channels, ksize=1):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels * (scale ** 2), kernel_size=1, stride=1, padding=ksize//2),\n",
    "            nn.PixelShuffle(scale)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.upsample(input)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, channels, ksize=3,\n",
    "                 use_instance_norm=False, affine=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.ksize = ksize\n",
    "        padding = self.ksize // 2\n",
    "        if use_instance_norm:\n",
    "            self.transform = nn.Sequential(\n",
    "                nn.ReflectionPad2d(padding),\n",
    "                nn.Conv2d(input_channels, channels, kernel_size=self.ksize, stride=1),\n",
    "                nn.InstanceNorm2d(channels, affine=affine),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.ReflectionPad2d(padding),\n",
    "                nn.Conv2d(channels, channels, kernel_size=self.ksize, stride=1),\n",
    "                nn.InstanceNorm2d(channels)\n",
    "            )\n",
    "        else:\n",
    "            self.transform = nn.Sequential(\n",
    "                nn.ReflectionPad2d(padding),\n",
    "                nn.Conv2d(input_channels, channels, kernel_size=self.ksize, stride=1),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.ReflectionPad2d(padding),\n",
    "                nn.Conv2d(channels, channels, kernel_size=self.ksize, stride=1),\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input + self.transform(input) * MULT_FACTOR\n",
    "\n",
    "\n",
    "class NormalizeBySum(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x / torch.sum(x, dim=1, keepdim=True).clamp(min=1e-7)\n",
    "\n",
    "\n",
    "class MeanShift(nn.Conv2d):\n",
    "    def __init__(self, rgb_range, rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\n",
    "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
    "        std = torch.Tensor(rgb_std)\n",
    "        self.weight.data = torch.eye(3).view(3, 3, 1, 1) / std.view(3, 1, 1, 1)\n",
    "        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean) / std\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "class DSN(nn.Module):\n",
    "    def __init__(self, k_size, input_channels=3, scale=4):\n",
    "        super(DSN, self).__init__()\n",
    "\n",
    "        self.k_size = k_size\n",
    "\n",
    "        self.sub_mean = MeanShift(1)\n",
    "\n",
    "        self.ds_1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(2),\n",
    "            nn.Conv2d(input_channels, 64, 5),\n",
    "            nn.LeakyReLU(LEAKY_FACTOR)\n",
    "        )\n",
    "\n",
    "        self.ds_2 = DownsampleBlock(2, 64, 128, ksize=1)\n",
    "        self.ds_4 = DownsampleBlock(2, 128, 128, ksize=1)\n",
    "\n",
    "        res_4 = list()\n",
    "        for idx in range(5):\n",
    "            res_4 += [ResidualBlock(128, 128)]\n",
    "        self.res_4 = nn.Sequential(*res_4)\n",
    "\n",
    "        self.ds_8 = DownsampleBlock(2, 128, 256)\n",
    "\n",
    "        self.kernels_trunk = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            UpsampleBlock(8 // scale, 256, 256, ksize=1),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.kernels_weight = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, k_size ** 2, 3)\n",
    "        )\n",
    "\n",
    "        self.offsets_trunk = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            UpsampleBlock(8 // scale, 256, 256, ksize=1),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.offsets_h_generation = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, k_size ** 2, 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.offsets_v_generation = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, k_size ** 2, 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sub_mean(x)\n",
    "\n",
    "        x = self.ds_1(x)\n",
    "        x = self.ds_2(x)\n",
    "        x = self.ds_4(x)\n",
    "        x = x + self.res_4(x)\n",
    "        x = self.ds_8(x)\n",
    "\n",
    "        kt = self.kernels_trunk(x)\n",
    "        k_weight = torch.clamp(self.kernels_weight(kt), min=1e-6, max=1)\n",
    "        kernels = k_weight / torch.sum(k_weight, dim=1, keepdim=True).clamp(min=1e-6)\n",
    "\n",
    "        ot = self.offsets_trunk(x)\n",
    "        offsets_h = self.offsets_h_generation(ot)\n",
    "        offsets_v = self.offsets_v_generation(ot)\n",
    "\n",
    "        return kernels, offsets_h, offsets_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boring-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load CAR/EDSR/common.py\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        padding=(kernel_size // 2), bias=bias)\n",
    "\n",
    "\n",
    "class MeanShift(nn.Conv2d):\n",
    "    def __init__(self, rgb_range, rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\n",
    "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
    "        std = torch.Tensor(rgb_std)\n",
    "        self.weight.data = torch.eye(3).view(3, 3, 1, 1) / std.view(3, 1, 1, 1)\n",
    "        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean) / std\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "            self, conv, in_channels, out_channels, kernel_size, stride=1, bias=False,\n",
    "            bn=True, act=nn.ReLU(True)):\n",
    "\n",
    "        m = [conv(in_channels, out_channels, kernel_size, bias=bias)]\n",
    "        if bn:\n",
    "            m.append(nn.BatchNorm2d(out_channels))\n",
    "        if act is not None:\n",
    "            m.append(act)\n",
    "\n",
    "        super(BasicBlock, self).__init__(*m)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, conv, n_feats, kernel_size,\n",
    "            bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
    "\n",
    "        super(ResBlock, self).__init__()\n",
    "        m = []\n",
    "        for i in range(2):\n",
    "            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm2d(n_feats))\n",
    "            if i == 0:\n",
    "                m.append(act)\n",
    "\n",
    "        self.body = nn.Sequential(*m)\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x).mul(self.res_scale)\n",
    "        res += x\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class Upsampler(nn.Sequential):\n",
    "    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\n",
    "\n",
    "        m = []\n",
    "        if (scale & (scale - 1)) == 0:  # Is scale = 2^n?\n",
    "            for _ in range(int(math.log(scale, 2))):\n",
    "                m.append(conv(n_feats, 4 * n_feats, 3, bias))\n",
    "                m.append(nn.PixelShuffle(2))\n",
    "                if bn:\n",
    "                    m.append(nn.BatchNorm2d(n_feats))\n",
    "                if act == 'relu':\n",
    "                    m.append(nn.ReLU(True))\n",
    "                elif act == 'prelu':\n",
    "                    m.append(nn.PReLU(n_feats))\n",
    "\n",
    "        elif scale == 3:\n",
    "            m.append(conv(n_feats, 9 * n_feats, 3, bias))\n",
    "            m.append(nn.PixelShuffle(3))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm2d(n_feats))\n",
    "            if act == 'relu':\n",
    "                m.append(nn.ReLU(True))\n",
    "            elif act == 'prelu':\n",
    "                m.append(nn.PReLU(n_feats))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        super(Upsampler, self).__init__(*m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "timely-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load CAR/utils.py\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import signal\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def matlab_style_gauss2D(shape=(3, 3), sigma=0.5):\n",
    "    \"\"\"\n",
    "    2D gaussian mask - should give the same result as MATLAB's fspecial('gaussian',[shape],[sigma])\n",
    "    Acknowledgement : https://stackoverflow.com/questions/17190649/how-to-obtain-a-gaussian-filter-in-python (Author@ali_m)\n",
    "    \"\"\"\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m + 1, -n:n + 1]\n",
    "    h = np.exp(-(x * x + y * y) / (2. * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h\n",
    "\n",
    "\n",
    "def calc_ssim(X, Y, sigma=1.5, K1=0.01, K2=0.03, R=255):\n",
    "    '''\n",
    "    X : y channel (i.e., luminance) of transformed YCbCr space of X\n",
    "    Y : y channel (i.e., luminance) of transformed YCbCr space of Y\n",
    "    Please follow the setting of psnr_ssim.m in EDSR (Enhanced Deep Residual Networks for Single Image Super-Resolution CVPRW2017).\n",
    "    Official Link : https://github.com/LimBee/NTIRE2017/tree/db34606c2844e89317aac8728a2de562ef1f8aba\n",
    "    The authors of EDSR use MATLAB's ssim as the evaluation tool,\n",
    "    thus this function is the same as ssim.m in MATLAB with C(3) == C(2)/2.\n",
    "    '''\n",
    "    gaussian_filter = matlab_style_gauss2D((11, 11), sigma)\n",
    "\n",
    "    X = X.astype(np.float64)\n",
    "    Y = Y.astype(np.float64)\n",
    "\n",
    "    window = gaussian_filter\n",
    "\n",
    "    ux = signal.convolve2d(X, window, mode='same', boundary='symm')\n",
    "    uy = signal.convolve2d(Y, window, mode='same', boundary='symm')\n",
    "\n",
    "    uxx = signal.convolve2d(X * X, window, mode='same', boundary='symm')\n",
    "    uyy = signal.convolve2d(Y * Y, window, mode='same', boundary='symm')\n",
    "    uxy = signal.convolve2d(X * Y, window, mode='same', boundary='symm')\n",
    "\n",
    "    vx = uxx - ux * ux\n",
    "    vy = uyy - uy * uy\n",
    "    vxy = uxy - ux * uy\n",
    "\n",
    "    C1 = (K1 * R) ** 2\n",
    "    C2 = (K2 * R) ** 2\n",
    "\n",
    "    A1, A2, B1, B2 = ((2 * ux * uy + C1, 2 * vxy + C2, ux ** 2 + uy ** 2 + C1, vx + vy + C2))\n",
    "    D = B1 * B2\n",
    "    S = (A1 * A2) / D\n",
    "    mssim = S.mean()\n",
    "\n",
    "    return mssim\n",
    "\n",
    "\n",
    "def cal_psnr(img_1, img_2, benchmark=False):\n",
    "    assert img_1.shape[0] == img_2.shape[0] and img_1.shape[1] == img_2.shape[1]\n",
    "    img_1 = np.float64(img_1)\n",
    "    img_2 = np.float64(img_2)\n",
    "\n",
    "    diff = (img_1 - img_2) / 255.0\n",
    "    if benchmark:\n",
    "        gray_coeff = np.array([65.738, 129.057, 25.064]).reshape(1, 1, 3) / 255.0\n",
    "        diff = diff * gray_coeff\n",
    "        diff = diff[:, :, 0] + diff[:, :, 1] + diff[:, :, 2]\n",
    "\n",
    "    mse = np.mean(diff ** 2)\n",
    "    psnr = -10.0 * np.log10(mse)\n",
    "\n",
    "    return psnr\n",
    "\n",
    "\n",
    "def load_img(img_file):\n",
    "    img = Image.open(img_file).convert('RGB')\n",
    "    img = np.array(img)\n",
    "    h, w, _ = img.shape\n",
    "    img = img[:h // 8 * 8, :w // 8 * 8, :]\n",
    "    img = np.array(img) / 255.\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    img = torch.from_numpy(img).float().unsqueeze(0)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "right-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load CAR/EDSR/edsr.py\n",
    "#from EDSR import common\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "url = {\n",
    "    'r16f64x2': 'https://cv.snu.ac.kr/research/EDSR/models/edsr_baseline_x2-1bc95232.pt',\n",
    "    'r16f64x3': 'https://cv.snu.ac.kr/research/EDSR/models/edsr_baseline_x3-abf2a44e.pt',\n",
    "    'r16f64x4': 'https://cv.snu.ac.kr/research/EDSR/models/edsr_baseline_x4-6b446fab.pt',\n",
    "    'r32f256x2': 'https://cv.snu.ac.kr/research/EDSR/models/edsr_x2-0edfb8a3.pt',\n",
    "    'r32f256x3': 'https://cv.snu.ac.kr/research/EDSR/models/edsr_x3-ea3ef2c6.pt',\n",
    "    'r32f256x4': 'https://cv.snu.ac.kr/research/EDSR/models/edsr_x4-4f62e9ef.pt'\n",
    "}\n",
    "\n",
    "\n",
    "class EDSR(nn.Module):\n",
    "    def __init__(self, n_resblocks=16, n_feats=64, scale=4, conv=default_conv):\n",
    "        super(EDSR, self).__init__()\n",
    "\n",
    "        # n_resblocks = 16 * 2\n",
    "        # n_feats = 64 * 4\n",
    "        kernel_size = 3\n",
    "        act = nn.ReLU(True)\n",
    "        self.url = url['r{}f{}x{}'.format(n_resblocks, n_feats, scale)]\n",
    "        self.sub_mean = MeanShift(1)\n",
    "        self.add_mean = MeanShift(1, sign=1)\n",
    "\n",
    "        # define head module\n",
    "        m_head = [conv(3, n_feats, kernel_size)]\n",
    "\n",
    "        # define body module\n",
    "        m_body = [\n",
    "            ResBlock(\n",
    "                conv, n_feats, kernel_size, act=act, res_scale=0.1\n",
    "            ) for _ in range(n_resblocks)\n",
    "        ]\n",
    "        m_body.append(conv(n_feats, n_feats, kernel_size))\n",
    "\n",
    "        # define tail module\n",
    "        m_tail = [\n",
    "            Upsampler(conv, scale, n_feats, act=False),\n",
    "            conv(n_feats, 3, kernel_size)\n",
    "        ]\n",
    "\n",
    "        self.head = nn.Sequential(*m_head)\n",
    "        self.body = nn.Sequential(*m_body)\n",
    "        self.tail = nn.Sequential(*m_tail)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sub_mean(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        res = self.body(x)\n",
    "        res += x\n",
    "\n",
    "        x = self.tail(res)\n",
    "        x = self.add_mean(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def load_state_dict(self, state_dict, strict=True):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name in own_state:\n",
    "                if isinstance(param, nn.Parameter):\n",
    "                    param = param.data\n",
    "                try:\n",
    "                    own_state[name].copy_(param)\n",
    "                except Exception:\n",
    "                    if name.find('tail') == -1:\n",
    "                        raise RuntimeError('While copying the parameter named {}, '\n",
    "                                           'whose dimensions in the model are {} and '\n",
    "                                           'whose dimensions in the checkpoint are {}.'\n",
    "                                           .format(name, own_state[name].size(), param.size()))\n",
    "            elif strict:\n",
    "                if name.find('tail') == -1:\n",
    "                    raise KeyError('unexpected key \"{}\" in state_dict'\n",
    "                                   .format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sexual-peninsula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALE = 4\n",
    "upscale_net = EDSR(32, 256, scale=4)\n",
    "upscale_net = nn.DataParallel(upscale_net, [0])\n",
    "upscale_net.load_state_dict(torch.load(os.path.join(\"./models\", '{0}x'.format(SCALE), 'usn.pth')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_image(url):\n",
    "#     return Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# dog_url = \"https://mbtimetraveler.files.wordpress.com/2016/01/sad-cute-dog-high-resolution-wallpaper-for-desktop-background-download-dog-photos-free.jpg?w=1800\"\n",
    "# im = download_image(dog_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bound-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dominican-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsample(img, r=0.1):\n",
    "#     \"\"\" downsample an image by a percentage\n",
    "#         :param img, a PIL Image format\n",
    "#         :r ratio, the percentage new image size\n",
    "#     \"\"\"\n",
    "#     width, height = img.size\n",
    "#     w = int(width*r)\n",
    "#     h = int(height*r)\n",
    "#     if 'P' in img.mode: # check if image is a palette type\n",
    "#         img = img.convert(\"RGB\") # convert it to RGB\n",
    "#         img = img.resize((w,h),Image.ANTIALIAS) # resize it\n",
    "#         img = img.convert(\"P\",dither=Image.NONE, palette=Image.ADAPTIVE) \n",
    "#            #convert back to palette\n",
    "#     else:\n",
    "#         img = img.resize((w,h),Image.ANTIALIAS) # regular resize\n",
    "#     return img\n",
    "\n",
    "# im_lr = downsample(im)\n",
    "# im_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-outline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nominated-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(\"data/Holopix50k/train/left/-Lq1T4_X3mJnj2rY41uw_left.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "neural-structure",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 900.00 MiB (GPU 0; 11.17 GiB total capacity; 9.85 GiB already allocated; 851.44 MiB free; 9.90 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b73ca2b9ede1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreconstructed_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupscale_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c6be202c3ba5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a4ee0bb39f05>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 900.00 MiB (GPU 0; 11.17 GiB total capacity; 9.85 GiB already allocated; 851.44 MiB free; 9.90 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "reconstructed_img = upscale_net(img / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-company",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-hearts",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-savings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-poetry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
